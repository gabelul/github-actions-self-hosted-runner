# Description: Matrix testing workflow for comprehensive cross-platform and multi-version testing
#
# This template provides extensive matrix testing capabilities including:
# - Multi-platform testing (Linux, macOS, Windows simulation)
# - Multiple runtime versions
# - Different dependency combinations
# - Environment variable matrices
# - Parallel execution with result aggregation
#
# Generated by workflow-helper.sh

name: Matrix Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 1'  # Weekly on Monday at 2 AM

env:
  FORCE_COLOR: 1
  CI: true

jobs:
  # Matrix strategy for comprehensive testing
  matrix-test:
    name: Test ${{ matrix.platform }}-${{ matrix.version }}-${{ matrix.variant }}
    runs-on: self-hosted

    strategy:
      # Don't cancel other jobs if one fails
      fail-fast: false
      matrix:
        # Platform simulation (using different containers/environments)
        platform:
          - linux
          - alpine
          - ubuntu-20
          - ubuntu-22

        # Runtime versions
        version:
          - '16'
          - '18'
          - '20'
          - 'latest'

        # Test variants
        variant:
          - minimal
          - full
          - production

        # Exclude problematic combinations
        exclude:
          # Alpine might not support older Node versions
          - platform: alpine
            version: '16'
          # Skip some combinations to reduce job count
          - platform: ubuntu-20
            version: 'latest'
            variant: minimal

        # Include special test cases
        include:
          # Test with specific configurations
          - platform: linux
            version: '18'
            variant: security
            extra_flags: '--security-audit'

          # Test with experimental features
          - platform: ubuntu-22
            version: 'latest'
            variant: experimental
            extra_flags: '--experimental'

    env:
      PLATFORM: ${{ matrix.platform }}
      VERSION: ${{ matrix.version }}
      VARIANT: ${{ matrix.variant }}
      EXTRA_FLAGS: ${{ matrix.extra_flags }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup test environment
        run: |
          echo "Setting up test environment"
          echo "Platform: ${{ matrix.platform }}"
          echo "Version: ${{ matrix.version }}"
          echo "Variant: ${{ matrix.variant }}"

          # Platform-specific setup
          case "${{ matrix.platform }}" in
            "alpine")
              echo "Setting up Alpine Linux environment"
              # Install Alpine-specific dependencies
              ;;
            "ubuntu-20")
              echo "Setting up Ubuntu 20.04 environment"
              # Install Ubuntu 20.04 specific dependencies
              ;;
            "ubuntu-22")
              echo "Setting up Ubuntu 22.04 environment"
              # Install Ubuntu 22.04 specific dependencies
              ;;
            *)
              echo "Setting up default Linux environment"
              ;;
          esac

      - name: Configure runtime version
        run: |
          echo "Configuring runtime for version ${{ matrix.version }}"

          # Version-specific configuration
          case "${{ matrix.version }}" in
            "16"|"18"|"20")
              echo "Using Node.js ${{ matrix.version }}"
              # Setup specific Node.js version
              ;;
            "latest")
              echo "Using latest Node.js version"
              # Setup latest version
              ;;
          esac

      - name: Install dependencies
        run: |
          echo "Installing dependencies for ${{ matrix.variant }} variant"

          case "${{ matrix.variant }}" in
            "minimal")
              echo "Installing minimal dependencies"
              # Install only essential dependencies
              ;;
            "full")
              echo "Installing full dependencies"
              # Install all dependencies including dev dependencies
              ;;
            "production")
              echo "Installing production dependencies"
              # Install only production dependencies
              ;;
            "security")
              echo "Installing security testing dependencies"
              # Install security testing tools
              ;;
            "experimental")
              echo "Installing experimental dependencies"
              # Install bleeding-edge dependencies
              ;;
          esac

      - name: Run variant-specific tests
        run: |
          echo "Running tests for ${{ matrix.variant }} variant"

          case "${{ matrix.variant }}" in
            "minimal")
              # Run basic unit tests only
              npm test -- --testPathPattern='unit'
              ;;
            "full")
              # Run all tests including integration and e2e
              npm run test:unit
              npm run test:integration
              npm run test:e2e
              ;;
            "production")
              # Run production-focused tests
              NODE_ENV=production npm test
              npm run test:production
              ;;
            "security")
              # Run security-specific tests
              npm audit --audit-level high
              npm run test:security
              ;;
            "experimental")
              # Run with experimental features enabled
              NODE_OPTIONS="--experimental-modules" npm test
              ;;
          esac

      - name: Platform-specific validations
        run: |
          echo "Running platform-specific validations"

          case "${{ matrix.platform }}" in
            "alpine")
              # Test Alpine-specific features
              echo "Validating Alpine Linux compatibility"
              ;;
            "ubuntu-20")
              # Test Ubuntu 20.04 specific features
              echo "Validating Ubuntu 20.04 compatibility"
              ;;
            "ubuntu-22")
              # Test Ubuntu 22.04 specific features
              echo "Validating Ubuntu 22.04 compatibility"
              ;;
          esac

      - name: Collect test artifacts
        if: always()
        run: |
          # Create artifacts directory
          mkdir -p artifacts/${{ matrix.platform }}-${{ matrix.version }}-${{ matrix.variant }}

          # Collect logs and reports
          if [ -f junit.xml ]; then
            cp junit.xml artifacts/${{ matrix.platform }}-${{ matrix.version }}-${{ matrix.variant }}/
          fi

          if [ -d coverage ]; then
            cp -r coverage artifacts/${{ matrix.platform }}-${{ matrix.version }}-${{ matrix.variant }}/
          fi

          # Platform-specific artifact collection
          case "${{ matrix.platform }}" in
            "alpine")
              # Collect Alpine-specific logs
              echo "Collecting Alpine-specific artifacts"
              ;;
          esac

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.platform }}-${{ matrix.version }}-${{ matrix.variant }}
          path: artifacts/
          retention-days: 30

  # Performance testing matrix
  performance-test:
    name: Performance Test ${{ matrix.load }}-${{ matrix.scenario }}
    runs-on: self-hosted

    strategy:
      matrix:
        load: [light, medium, heavy]
        scenario: [basic, complex, stress]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup performance testing
        run: |
          echo "Setting up performance testing"
          echo "Load: ${{ matrix.load }}"
          echo "Scenario: ${{ matrix.scenario }}"

      - name: Run performance tests
        run: |
          case "${{ matrix.load }}" in
            "light")
              CONCURRENT_USERS=10
              DURATION=60
              ;;
            "medium")
              CONCURRENT_USERS=50
              DURATION=300
              ;;
            "heavy")
              CONCURRENT_USERS=100
              DURATION=600
              ;;
          esac

          echo "Running performance test with $CONCURRENT_USERS users for ${DURATION}s"
          # Add your performance testing commands here

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: performance-${{ matrix.load }}-${{ matrix.scenario }}
          path: performance-results/

  # Aggregate results from all matrix jobs
  aggregate-results:
    name: Aggregate Test Results
    runs-on: self-hosted
    needs: [matrix-test, performance-test]
    if: always()

    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v4

      - name: Aggregate test results
        run: |
          echo "Aggregating test results from all matrix jobs"

          # Count total tests, passed, failed
          TOTAL_JOBS=0
          PASSED_JOBS=0
          FAILED_JOBS=0

          # Process matrix-test results
          for dir in test-results-*; do
            if [ -d "$dir" ]; then
              TOTAL_JOBS=$((TOTAL_JOBS + 1))
              if [ -f "$dir/junit.xml" ]; then
                # Parse junit.xml to check if tests passed
                if grep -q 'failures="0"' "$dir/junit.xml"; then
                  PASSED_JOBS=$((PASSED_JOBS + 1))
                else
                  FAILED_JOBS=$((FAILED_JOBS + 1))
                fi
              fi
            fi
          done

          echo "Matrix Test Summary:"
          echo "Total jobs: $TOTAL_JOBS"
          echo "Passed jobs: $PASSED_JOBS"
          echo "Failed jobs: $FAILED_JOBS"

          # Generate summary report
          cat > test-summary.md << EOF
          # Matrix Test Summary

          ## Results Overview
          - **Total Jobs**: $TOTAL_JOBS
          - **Passed Jobs**: $PASSED_JOBS ✅
          - **Failed Jobs**: $FAILED_JOBS ❌
          - **Success Rate**: $(( (PASSED_JOBS * 100) / TOTAL_JOBS ))%

          ## Matrix Coverage
          - Platforms tested: linux, alpine, ubuntu-20, ubuntu-22
          - Versions tested: 16, 18, 20, latest
          - Variants tested: minimal, full, production, security, experimental

          ## Performance Testing
          - Load scenarios: light, medium, heavy
          - Test scenarios: basic, complex, stress
          EOF

      - name: Upload aggregated results
        uses: actions/upload-artifact@v4
        with:
          name: aggregated-results
          path: |
            test-summary.md
            *.json
            *.xml

      - name: Create test report
        if: always()
        run: |
          echo "## 📊 Matrix Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat test-summary.md >> $GITHUB_STEP_SUMMARY

  # Send notifications about test results
  notify:
    name: Send Notifications
    runs-on: self-hosted
    needs: [aggregate-results]
    if: always()

    steps:
      - name: Notify on success
        if: needs.aggregate-results.result == 'success'
        run: |
          echo "✅ All matrix tests passed successfully!"
          # Send success notification (Slack, Discord, etc.)

      - name: Notify on failure
        if: needs.aggregate-results.result == 'failure'
        run: |
          echo "❌ Some matrix tests failed"
          # Send failure notification with details